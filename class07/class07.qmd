---
title: "Class 7: Machine Learning I"
author: "Cynthia Lin"
format: gfm
---

## K-means

Make up some input data where we know what the answer should be

```{r}
tmp <- c( rnorm(30, -3), rnorm(30, +3) )
x <- cbind( x= tmp, y= rev(tmp))
head(x)
```
Quick plot of x to see the two groups at -3,+3 and +3,-3
```{r}
 plot(x)
```

Use the `kmeans()` function setting k to 2 and nstart=20

```{r}
km <- kmeans(x, centers = 2, nstart=20)
km
```
> Q. What component if your result object details 
  -cluster assignment / membership?
  cluster center? 
  
```{r}
km$cluster
```
```{r}
km$centers
```

> Q. Plot x colored y the kmeans cluster assignment and add cluster centers as blue points.  

```{r}
plot( x, col= km$cluster)
points(km$centers, col = "blue", pch=15, cex = 2)
```
PLay with kmeans and ask for different number of clusters
```{r}
km <- kmeans(x, centers = 4, nstart = 20)
plot(x, col= km$cluster)
points(km$centers, col = "blue", pch = 16, cex =2)
```
# Hierarchical Clustering

This is another very useful and widely employed clustering method which has the advnatage over kmeans in that it can help reveal the somethign of the true grouping in your data.

The `hclust()` function wants a distance matrix as input. We can get this from the `dist()` function. 

```{r}
d <- dist(x)
hc <- hclust(d)
hc
```
There is a plot method for hclust results:

```{r}
plot(hc)
abline(h=10, col = "red")
```

To get my cluster membership vector I need to "cut" my tree to yield sub-trees or branches with all the members of a given cluster residing on the same cut branch. The function to do this is called `cutree()`

```{r}
grps <- cutree(hc, h=10)
grps
```

It is often helpful to use the `k=` argument to cutree rather than the `h=` height of cutting with 'cutree()`. This will cut the tree to yield the number of clusters you want. 
```{r}
cutree(hc, k =4)
```
# Principal Component Analysis (PCA)

The base R function for PCA is called `prcomp()`
Lets play with some 17D data (very small data set) and see how PCA can help.

## PCA of UK food data

Import the data

```{r}
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
head(x)
```
**Q1. How many rows and columns are in your new data frame named x? What R functions could you use to answer this questions?**

```{r}
dim(x)
```
Preview the first 6 rows

```{r}
head(x)
```
# Note how the minus indexing works

```{r}
rownames(x) <- x[,1]
x <- x[,-1]
head(x)
```
```{r}
dim(x)
```
```{r}
x <- read.csv(url, row.names=1)
head(x)
```
**Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?**

I prefer the second approach better because it is more condensed and shorter. Furthermore, the first approach code block starts deleting columns once you run it multiple times. Therefore the second approach code is more robust and sustainable.

Spotting major differences and trends
```{r}
barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))

```
**Q3: Changing what optional argument in the above barplot() function results in the following plot?**
Changing the `beside=T` to `beside =False` has made the bar plots wider and combined instead of displayed as a distribution. Leaving this argument out has the same effect as it being false because each bar of the plot will correspond to being stacked. 

**Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?**

```{r}
pairs(x, col=rainbow(10), pch=16)
```
 I think that it is difficult ot make sense of this data. If a given point is on the diagonal for a given plot, I think that it means that it follows the line of best fit and follows the trends of the data. I think that it also shows the density and level of correlation between the variables. 

**Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?**
The main differences between N. Ireland and the other countries of the UK in terms of this data set would be that N. Ireland eats the most carcass meat and least amount of fish.


```{r}
pca <- prcomp( t(x))
summary(pca)
```
 a "PCA plot" (a.k.a. "Score Plot", PC1vsPC2 plot, etc.) 
 
```{r}
pca$x
```

```{r}
# Use the prcomp() PCA function 
pca <- prcomp( t(x) )
summary(pca)
```

**Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the data points.**
# Plot PC1 vs PC2
```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500))
text(pca$x[,1], pca$x[,2], colnames(x))
```

**Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland map and table at start of this document.**
```{r}
plot(pca$x[,1], pca$x[,2], xlab="PC1", ylab="PC2", xlim=c(-270,500), 
     col=c("orange", "red","blue", "darkgreen"), pch=15)
text(pca$x[,1], pca$x[,2], 
     colnames(x), col=c("orange", "red", "blue", "darkgreen"), 
     pch=15)
```


```{r}
v <- round( pca$sdev^2/sum(pca$sdev^2) * 100 )
v
```
```{r}
## or the second row here...
z <- summary(pca)
z$importance
```
```{r}
barplot(v, xlab="Principal Component", ylab="Percent Variation")
```

##Digging deeper (variable loadings)
```{r}
## Lets focus on PC1 as it accounts for > 90% of variance 
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )
```






